{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrO4YcXhf27s",
        "outputId": "b0cba296-44be-4702-e66f-3ef70133c855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==2.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu2iAY5Tf_iG",
        "outputId": "ab2bd62b-1573-4a7a-bfa9-1dcd2d8640b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Downloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m127.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.0 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchtext==0.15.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zP6G75egBq5",
        "outputId": "581524a0-ea72-4384-ef03-fb159d7818ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.15.1\n",
            "  Downloading torchtext-0.15.1-cp311-cp311-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (2.32.3)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (2.0.2)\n",
            "Collecting torchdata==0.6.0 (from torchtext==0.15.1)\n",
            "  Downloading torchdata-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (892 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.0->torchtext==0.15.1) (2.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (18.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0->torchtext==0.15.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0->torchtext==0.15.1) (1.3.0)\n",
            "Downloading torchtext-0.15.1-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchdata, torchtext\n",
            "Successfully installed torchdata-0.6.0 torchtext-0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install indic-nlp-library"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjPW2MSAgiIC",
        "outputId": "4fb109ac-0ef4-421c-c8a1-f3199c6ab159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting sphinx-argparse (from indic-nlp-library)\n",
            "  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting sphinx-rtd-theme (from indic-nlp-library)\n",
            "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting morfessor (from indic-nlp-library)\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2025.2)\n",
            "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library) (8.2.3)\n",
            "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.17.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.6)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.19.1)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.3)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.0)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (24.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2025.4.26)\n",
            "Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Downloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\n",
            "Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: morfessor, sphinxcontrib-jquery, sphinx-argparse, sphinx-rtd-theme, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.92 morfessor-2.0.6 sphinx-argparse-0.5.2 sphinx-rtd-theme-3.0.2 sphinxcontrib-jquery-4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time\n",
        "import spacy\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from torch.nn.functional import pad\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import torchtext.datasets as datasets\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch.utils.data import DataLoader,Dataset,random_split\n",
        "\n"
      ],
      "metadata": {
        "id": "ifPwlUq1gkb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxRn2nk7gm9z",
        "outputId": "9e60a77f-db90-4d02-9cd4-4ffe60381a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from indicnlp.tokenize import indic_tokenize  # Telugu tokenizer from indic-nlp-library\n",
        "import random\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Function to read your custom dataset\n",
        "def read_telugu_english_data(file_paths):\n",
        "    with open(file_paths, 'r', encoding='utf-8') as file:\n",
        "        raw_datas = []\n",
        "        for line in file:\n",
        "            telugu_sentence, english_sentence = line.strip().split('>>')\n",
        "            raw_datas.append((telugu_sentence, english_sentence))\n",
        "    return raw_datas\n",
        "\n",
        "# Splitting the dataset\n",
        "def split_datasets(data, train_split=0.7, val_split=0.15, test_split=0.15):\n",
        "    total_sizes = len(data)\n",
        "    train_sizes = int(total_sizes * train_split)\n",
        "    val_sizes = int(total_sizes * val_split)\n",
        "    test_sizes = total_sizes - train_sizes - val_sizes\n",
        "    train_data, remaining_data = random_split(data, [train_sizes, total_sizes - train_sizes])\n",
        "    val_data, test_data = random_split(remaining_data, [val_sizes, test_sizes])\n",
        "    return list(train_data), list(val_data), list(test_data)\n",
        "\n",
        "# Custom Dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def get_raw_textss(self):\n",
        "        return [(srcs, trgs) for srcs, trgs in self.data]\n",
        "\n",
        "tokenizer_te = spacy.blank(\"xx\").tokenizer  # Telugu tokenizer\n",
        "tokenizer_ens = spacy.blank(\"en\").tokenizer  # English tokenizer\n",
        "\n",
        "# Build vocabulary function\n",
        "def build_vocabularys(tokenizer, dataset, min_freq=2):\n",
        "    def yield_tokenss(data):\n",
        "        for srcs, trgs in data:\n",
        "            yield [token.text for token in tokenizer(srcs)]\n",
        "            yield [token.text for token in tokenizer(trgs)]\n",
        "\n",
        "    vocabs = build_vocab_from_iterator(yield_tokenss(dataset.get_raw_textss()), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"], min_freq=min_freq)\n",
        "    vocabs.set_default_index(vocabs['<unk>'])  # Set default index for unknown tokenss\n",
        "    return vocabs\n",
        "\n",
        "# Read the dataset\n",
        "file_paths = '/content/drive/MyDrive/eng-tel.txt'\n",
        "raw_datas = read_telugu_english_data(file_paths)\n",
        "train_data_raw, val_data_raw, test_data_raw = split_datasets(raw_datas)\n",
        "\n",
        "# Create datasets\n",
        "train_datasets = CustomDataset(train_data_raw)\n",
        "valid_datasets = CustomDataset(val_data_raw)\n",
        "test_datasets = CustomDataset(test_data_raw)\n",
        "\n",
        "# Load vocabularies\n",
        "vocab_src = build_vocabularys(tokenizer_ens, train_datasets)\n",
        "vocab_trg = build_vocabularys(tokenizer_te, train_datasets)\n",
        "# Build vocabs\n",
        "vocab_en = build_vocabularys(tokenizer_ens, train_datasets)\n",
        "vocab_te = build_vocabularys(tokenizer_te, train_datasets)\n",
        "import pickle\n",
        "\n",
        "# Save the vocabs to your Google Drive\n",
        "with open('/content/drive/MyDrive/vocabs-eng.pkl', 'wb') as f:\n",
        "    pickle.dump(vocab_en, f)\n",
        "with open('/content/drive/MyDrive/vocabs-tel.pkl', 'wb') as f:\n",
        "    pickle.dump(vocab_te, f)\n",
        "# Batch generation function\n",
        "def generate_batchs(data_batch):\n",
        "    de_batch, en_batch = [], []\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    for (de_item, en_item) in data_batch:\n",
        "        # Convert list of indices into tensors\n",
        "        de_indices = torch.tensor([vocab_src[token.text] for token in tokenizer_te(de_item)], dtype=torch.long)\n",
        "        en_indices = torch.tensor([vocab_trg[token.text] for token in tokenizer_ens(en_item)], dtype=torch.long)\n",
        "\n",
        "        # Concatenate BOS, indices, EOS\n",
        "        de_temp = torch.cat([torch.tensor([vocab_src['<bos>']], dtype=torch.long), de_indices, torch.tensor([vocab_src['<eos>']], dtype=torch.long)], dim=0).to(device)\n",
        "        en_temp = torch.cat([torch.tensor([vocab_trg['<bos>']], dtype=torch.long), en_indices, torch.tensor([vocab_trg['<eos>']], dtype=torch.long)], dim=0).to(device)\n",
        "\n",
        "        # Pad sequences to ensure consistent length\n",
        "        padded_de = F.pad(de_temp, (0, MAX_PADDING - len(de_temp)), value=vocab_src['<pad>'])\n",
        "        padded_en = F.pad(en_temp, (0, MAX_PADDING - len(en_temp)), value=vocab_trg['<pad>'])\n",
        "\n",
        "        de_batch.append(padded_de)\n",
        "        en_batch.append(padded_en)\n",
        "\n",
        "    return torch.stack(de_batch), torch.stack(en_batch)\n",
        "\n",
        "# DataLoader setup\n",
        "BATCH_SIZE = 32\n",
        "train_iters = DataLoader(train_datasets, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=generate_batchs)\n",
        "valid_iters = DataLoader(valid_datasets, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=generate_batchs)\n",
        "test_iters = DataLoader(test_datasets, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=generate_batchs)\n",
        "\n",
        "BOS_IDX = vocab_trg['<bos>']\n",
        "EOS_IDX = vocab_trg['<eos>']\n",
        "PAD_IDX = vocab_trg['<pad>']\n",
        "MAX_PADDING = 150\n",
        "BATCH_SIZE= 32"
      ],
      "metadata": {
        "id": "0IcvJMr8rOcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddingss(nn.Module):\n",
        "  def __init__(self, vocab_size: int, d_model: int):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      vocab_size:    size of vocabulary\n",
        "      d_model:       dimension of embeddings\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.lut = nn.Embedding(vocab_size, d_model)\n",
        "    self.d_model = d_model\n",
        "\n",
        "  def forward(self, xs):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      xs:        input tensor (batch_sizes, sseq_lenght)\n",
        "\n",
        "      returns:  embedding vector\n",
        "    \"\"\"\n",
        "    # xs = xs.to(self.lut.weight.devices)\n",
        "    return (self.lut(xs) * math.sqrt(self.d_model))"
      ],
      "metadata": {
        "id": "GK7Z0H-RrRcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncodings(nn.Module):\n",
        "  def __init__(self, d_model: int, dropout: float = 0.1, max_length: int = 5000):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      d_model:     dimension of embeddings\n",
        "      dropout:     randomly zeroes-out some of the input\n",
        "      max_lenght:  amx sequence length\n",
        "    \"\"\"\n",
        "\n",
        "    super().__init__()\n",
        "    self.dropout=nn.Dropout(p=dropout)\n",
        "    pes=torch.zeros(max_length,d_model)\n",
        "    for k in np.arange(max_length):\n",
        "      for i in np.arange(d_model//2):\n",
        "        thetas = k / (100** ((2*i)/d_model))\n",
        "\n",
        "\n",
        "        pes[k, 2*i] = math.sin(thetas)\n",
        "\n",
        "\n",
        "        pes[k, 2*i+1] = math.cos(thetas)\n",
        "        self.register_buffer(\"pes\",pes)\n",
        "\n",
        "  def forward(self, xs):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      xs:        embeddings (batch_sizes, seq_lenght, d_model)\n",
        "      returns:  embeddings + positonal encodings (batch_sizes, seq_lengths, d_model)\n",
        "    \"\"\"\n",
        "    self.pes=self.pes.to(xs.device)\n",
        "    xs = xs + self.pes[:xs.size(1), :].requires_grad_(False)\n",
        "    return self.dropout(xs)"
      ],
      "metadata": {
        "id": "Q4AWAtZrxv_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentions(nn.Module):\n",
        "  def __init__(self, d_model, n_heads, dropout: float = 0.1):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      d_model:      dimension of embeddings\n",
        "      n_heads:      number of self attention heads\n",
        "      dropout:      probability of dropout occuring\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.n_heads = n_heads\n",
        "    self.d_key = d_model // n_heads\n",
        "\n",
        "    # create query, key, value, outputs weights\n",
        "    self.Wq = nn.Linear(d_model, d_model)\n",
        "    self.Wk = nn.Linear(d_model,d_model)\n",
        "    self.Wv = nn.Linear(d_model,d_model)\n",
        "    self.Wo = nn.Linear(d_model,d_model)\n",
        "\n",
        "    self.dropout = nn.Dropout(p = dropout)\n",
        "\n",
        "  def forward(self, query, key, value, masks = None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      query:    query vector (batch_sizes, q_length, d_model)\n",
        "      key:      key vector (batch_sizes, k_length, d_model)\n",
        "      value:    value vector (batch_sizes, s_length, d_model)\n",
        "      masks:     masks for decoders\n",
        "\n",
        "    Returns:\n",
        "      outputs:    attention values (batch_sizes, q_lenght, d_model)\n",
        "      attn_probss:  softmax scoress (batchsize, n_heads, q_length, k_length)\n",
        "    \"\"\"\n",
        "    batch_sizes = query.shape[0]\n",
        "\n",
        "    # calculate query, key, and value tensors\n",
        "    Qs = self.Wq(query)\n",
        "    Ks = self.Wk(key)          # (32, 10, 512) xs (512, 512) = (32, 10, 512)\n",
        "    Vs = self.Wv(value)\n",
        "\n",
        "    # split each tensor into n_heads to compute attention\n",
        "\n",
        "    # query tensor\n",
        "    Qs = Qs.view(batch_sizes,\n",
        "               -1,                                    # (32, 10, 512) -> (32, 10, 8 ,64)\n",
        "               self.n_heads,                          # -1 = q_lenght\n",
        "               self.d_key).permute(0, 2, 1, 3)        # (32, 10, 8, 64) -> (32, 8, 10, 64)\n",
        "\n",
        "    # key tensor\n",
        "    Ks = Ks.view(batch_sizes,\n",
        "               -1,\n",
        "               self.n_heads,\n",
        "               self.d_key).permute(0, 2, 1, 3)\n",
        "\n",
        "    # value tensor\n",
        "    Vs = Vs.view(batch_sizes,\n",
        "               -1,\n",
        "               self.n_heads,\n",
        "               self.d_key).permute(0, 2, 1, 3)\n",
        "\n",
        "    # computes attention\n",
        "    # scalled dot product -> QK^{T}\n",
        "    scaled_dot_prod = torch.matmul(Qs, Ks.permute(0, 1, 3, 2)) / math.sqrt(self.d_key)\n",
        "\n",
        "    # scaled_dot_prod = scaled_dot_prod.to(masks.devices)\n",
        "\n",
        "    # fill thoes positions of product as (-1e10) where masks positions are 0\n",
        "    if masks is not None:\n",
        "      scaled_dot_prod = scaled_dot_prod.masked_fill(masks == 0, -1e10)\n",
        "\n",
        "    attn_probss = torch.softmax(scaled_dot_prod, dim = -1)\n",
        "\n",
        "    # attn_probss = attn_probss.to(Vs.devices)\n",
        "\n",
        "    # multiply by values to get attention\n",
        "    As = torch.matmul(self.dropout(attn_probss), Vs)\n",
        "\n",
        "\n",
        "    # reshape attention back to (32, 10, 512)\n",
        "    As = As.permute(0,2,1,3).contiguous()               # (32, 8, 10, 64) -> (32, 10, 8 ,64)\n",
        "    As = As.view(batch_sizes, -1, self.n_heads*self.d_key)     # (32, 10, 8, 64) -> (32, 10, 8*64) = (32, 10, 512)\n",
        "\n",
        "    outputs = self.Wo(As)\n",
        "\n",
        "    return outputs, attn_probss"
      ],
      "metadata": {
        "id": "B9A6KR0pyFxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedForwards(nn.Module):\n",
        "  def __init__(self, d_model: int, d_ffn: int, dropout: float = 0.1):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      d_model:      dimension of embeddings\n",
        "      d_ffn:        dimension of feed-forwards network\n",
        "      dropout:      probability of dropout occuring\n",
        "    \"\"\"\n",
        "\n",
        "    super().__init__()\n",
        "    self.linear_layer_1 = nn.Linear(d_model, d_ffn)\n",
        "    self.linear_layer_2 = nn.Linear(d_ffn, d_model)\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "  def forward(self, xs):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      xs:        outputs from attention (batch_sizes, seq_lengths, d_model)\n",
        "\n",
        "    Returns:\n",
        "      expanded-and-contracted representation (batch_sizes, seq_lengths, d_model)\n",
        "    \"\"\"\n",
        "\n",
        "    return self.linear_layer_2(self.dropout(self.linear_layer_1(xs).relu()))"
      ],
      "metadata": {
        "id": "PpM3OEpwyeQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayers(nn.Module):\n",
        "  def __init__(self, d_model: int, n_heads: int, d_ffn: int, dropout: float):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      d_model:      dimension of embeddings\n",
        "      n_heads:      number of heads\n",
        "      d_ffn:        dimension of feed-forwards network\n",
        "      dropout:      probability of dropout ocurring\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.attention = MultiHeadAttentions(d_model, n_heads, dropout)\n",
        "    self.attn_layer_norm = nn.LayerNorm(d_model)\n",
        "    self.positionwise_fnn = PositionwiseFeedForwards(d_model, d_ffn, dropout)\n",
        "    self.fnn_layer_norm = nn.LayerNorm(d_model)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, srcs, src_masks):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      srcs:      positionally embedded sequences (batch_sizes, seq_lengths, d_model)\n",
        "      src_masks: masks for the sequences (batch_sizes, 1, 1, seq_lenght)\n",
        "    Returns:\n",
        "      srcs:      Sequences after self-attention (batch_sizes, seq_lengths, d_model)\n",
        "    \"\"\"\n",
        "\n",
        "    _srcs, attn_probss = self.attention(srcs, srcs, srcs, src_masks)\n",
        "\n",
        "    srcs = self.attn_layer_norm(srcs + self.dropout(_srcs))\n",
        "\n",
        "    _srcs = self.positionwise_fnn(srcs)\n",
        "\n",
        "    srcs = self.fnn_layer_norm(srcs + self.dropout(_srcs))\n",
        "\n",
        "    return srcs, attn_probss\n",
        "\n",
        "\n",
        "class Encoders(nn.Module):\n",
        "  def __init__(self, d_model: int, n_layers: int, n_heads: int, d_ffn: int, dropout: float = 0.1):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      d_model:      dimension of embeddings\n",
        "      n_layers:     number of encoders layers\n",
        "      n_heads:      number of heads\n",
        "      d_ffn:        dimension of feed-forwards network\n",
        "      dropout:      probability of dropout occuring\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "\n",
        "    # create n_layers encoders\n",
        "    self.layers = nn.ModuleList([EncoderLayers(d_model, n_heads, d_ffn, dropout) for _ in range(n_layers)])\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, srcs, src_masks):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      srcs:      positionally embedded sequences (batch_sizes, seq_lengths, d_model)\n",
        "      src_masks: masks for the sequences (batch_sizes, 1, 1, seq_lenght)\n",
        "    Returns:\n",
        "      srcs:      Sequences after self-attention (batch_sizes, seq_lengths, d_model)\n",
        "    \"\"\"\n",
        "\n",
        "    # Pass the sequence through each encoders\n",
        "    for layer in self.layers:\n",
        "      srcs, attn_probss = layer(srcs, src_masks)\n",
        "\n",
        "    self.attn_probss = attn_probss\n",
        "    return srcs"
      ],
      "metadata": {
        "id": "8JULOE0EymJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayers(nn.Module):\n",
        "  def __init__(self, d_model: int, n_heads: int, d_ffn: int, dropout: float):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      d_model:      dimension of embeddings\n",
        "      n_heads:      number of heads\n",
        "      d_ffn:        dimension of feed-forwards network\n",
        "      dropout:      probability of dropout occuring\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.masked_attention = MultiHeadAttentions(d_model, n_heads, dropout)\n",
        "    self.masked_attn_layer_norm = nn.LayerNorm(d_model)\n",
        "    self.attention = MultiHeadAttentions(d_model, n_heads, dropout)\n",
        "    self.attn_layer_norm = nn.LayerNorm(d_model)\n",
        "    self.positionwise_fnn = PositionwiseFeedForwards(d_model, d_ffn, dropout)\n",
        "    self.fnn_layer_norm = nn.LayerNorm(d_model)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, trgs, srcs, trg_masks, src_masks):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      trgs:          embedded sequences (batch_sizes, trg_seq_length, d_model)\n",
        "      srcs:          embedded sequences (batch_sizes, src_seq_length, d_model)\n",
        "      trg_masks:     masks for the sequences (batch_sizes, 1, trg_seq_length, trg_seq_lengt\n",
        "      src_masks:     masks for the sequences (batch_sizes, 1, 1, src_seq_length)\n",
        "\n",
        "    Returns:\n",
        "      trgs: sequences after self-attention (batch_sizes, trg_seq_length, d_model)\n",
        "      attn_probss: self-attention softmax scoress (batch_sizes, n_heads, trg_seq_length, src_seq_lenght)\n",
        "    \"\"\"\n",
        "\n",
        "    _trgs, attn_probss = self.masked_attention(trgs, trgs, trgs, trg_masks)\n",
        "\n",
        "    trgs = self.masked_attn_layer_norm(trgs + self.dropout(_trgs))\n",
        "\n",
        "    _trgs, attn_probss = self.attention(trgs, srcs, srcs, src_masks)\n",
        "\n",
        "    trgs = self.attn_layer_norm(trgs + self.dropout(_trgs))\n",
        "\n",
        "    _trgs = self.positionwise_fnn(trgs)\n",
        "\n",
        "    trgs = self.fnn_layer_norm(trgs + self.dropout(_trgs))\n",
        "\n",
        "    return trgs, attn_probss\n",
        "\n",
        "class Decoders(nn.Module):\n",
        "  def __init__(self, vocab_size: int, d_model: int, n_layers: int, n_heads: int, d_ffn: int, dropout: float = 0.1):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      vocab_size:     size of the target vocabulary\n",
        "      d_model:        dimension of embeddings\n",
        "      n_layers:       number of encoders layers\n",
        "      n_heads:        number of heads\n",
        "      d_ffn:          dimension of feed-forwards network\n",
        "      dropout:        probability of dropout occurring\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "\n",
        "    # create n_layers encoders\n",
        "    self.layers = nn.ModuleList([DecoderLayers(d_model, n_heads, d_ffn, dropout) for _ in range(n_layers)])\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # set outputs layer\n",
        "    self.Wo = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "  def forward(self, trgs, srcs, trg_masks, src_masks):\n",
        "      \"\"\"\n",
        "      Args:\n",
        "        trgs:          embedded sequences (batch_sizes, trg_seq_length, d_model)\n",
        "        srcs:          embedded sequences (batch_sizes, src_seq_length, d_model)\n",
        "        trg_masks:     masks for the sequences (batch_sizes, 1, trg_seq_length, trg_seq_lengt\n",
        "        src_masks:     masks for the sequences (batch_sizes, 1, 1, src_seq_length)\n",
        "\n",
        "      Returns:\n",
        "        outputs:       sequences after decoders (batch_sizes, trg_seq_length, vocab_size)\n",
        "        attn_probss:   self-attention softmax scoress (batch_sizes, n_heads, trg_seq_length, src_seq\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "      # pass the sequences through each decoders\n",
        "      for layer in self.layers:\n",
        "        trgs , attn_probss = layer(trgs, srcs, trg_masks, src_masks)\n",
        "\n",
        "      self.attn_probss = attn_probss\n",
        "      return self.Wo(trgs)\n"
      ],
      "metadata": {
        "id": "uI-GLwGizNj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformers(nn.Module):\n",
        "  def __init__(self, encoders: Encoders, decoders: Decoders, src_embeds: Embeddingss,\n",
        "               trg_embeds: Embeddingss, src_pad_idx: int, trg_pad_idx: int, device):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      encoders:        encoders stack\n",
        "      decoders:        decoders stack\n",
        "      src_embeds:      source embeddings and encodings\n",
        "      trg_embeds:      target embeddings and encodings\n",
        "      src_pad_idx:    padding index\n",
        "\n",
        "      trg_pad_idx:    padding index\n",
        "      devices:         cpu or gpu\n",
        "\n",
        "    Returns:\n",
        "      outputs:         sequences after decoders (batch_sizes, trg_seq_length, vocab_size)\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoders = encoders\n",
        "    self.decoders = decoders\n",
        "    self.src_embeds = src_embeds\n",
        "    self.trg_embeds = trg_embeds\n",
        "    self.device = device\n",
        "    self.src_pad_idx = src_pad_idx\n",
        "    self.trg_pad_idx = trg_pad_idx\n",
        "\n",
        "  def make_src_masks(self, srcs):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      srcs:        raws sequence with padding     (batch_sizes, seq_lengths)\n",
        "\n",
        "    Returns:\n",
        "      src_masks:   masks for each sequence        (batch_sizes, 1, 1, seq_lenght)\n",
        "    \"\"\"\n",
        "    # assign 1 to tokenss that need attended to and 0 to padding tokenss, then add 2 dimensions\n",
        "    src_masks = (srcs != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    return src_masks\n",
        "\n",
        "  def make_trg_masks(self, trgs):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      trgs:        raws sequence with padding     (batch_sizes, seq_lengths)\n",
        "\n",
        "    Returns:\n",
        "      trg_masks:   masks for each sequence        (batch_sizes, 1, seq_lengths, seq_lenght)\n",
        "    \"\"\"\n",
        "    seq_lengths = trgs.shape[1]\n",
        "\n",
        "    # assign True to tokenss that need attended to and False to padding tokenss, then add 2 dimensions\n",
        "    trg_masks = (trgs != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    # generate subsequent masks\n",
        "    trg_sub_masks = torch.tril(torch.ones((seq_lengths, seq_lengths), device = self.device )).bool()\n",
        "\n",
        "    # bitwise \"and\" operator\n",
        "    trg_masks = trg_masks & trg_sub_masks\n",
        "    return trg_masks\n",
        "\n",
        "  def forward(self, srcs, trgs):\n",
        "    \"\"\"\n",
        "    Args\n",
        "      trgs:        raws target sequence (batch_sizes, trg_seq_length)\n",
        "      srcs:        raws srcs sequences (batch_sizes, src_seq_length)\n",
        "\n",
        "    Returns:\n",
        "      outputs:     sequences after decoders   (batch_sizes, trg_seq_length, output_dim)\n",
        "    \"\"\"\n",
        "\n",
        "    # create source and target masks\n",
        "    src_masks = self.make_src_masks(srcs)    #(batch_sizes, 1, 1, src_seq_length)\n",
        "    trg_masks = self.make_trg_masks(trgs)    #(batch_sizes, 1, trg_seq_length, trg_seq_length)\n",
        "\n",
        "    # push the srcs through the encoders layers\n",
        "    srcs = self.encoders(self.src_embeds(srcs), src_masks)   # (batch_sizes, src_seq_length, d_model)\n",
        "\n",
        "    # decoders outputs and attention probabilities\n",
        "    outputs = self.decoders(self.trg_embeds(trgs), srcs, trg_masks, src_masks)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "YhTbBCrUpAX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_models(device, src_vocab, trg_vocab, n_layers: int = 3, d_model: int = 128,\n",
        "               d_ffn: int = 256, n_heads: int = 8, dropout: float = 0.1,\n",
        "               max_length : int = 80):\n",
        "  \"\"\"\n",
        "    Construct a models when provided parameters.\n",
        "\n",
        "    Args:\n",
        "      src_vocab:      source vocubulary\n",
        "      trg_vocab:      target vocubulary\n",
        "      n_layers:       Number of encoders and decoders\n",
        "      d_model:        dimension of embeddinsg\n",
        "      d_ffn:          dimension of feed-forwaed network\n",
        "      n_heads:        number of heads\n",
        "      dropout:        probability of dropout ocurring\n",
        "      max_length:     maximum sequence length for positional encodings\n",
        "\n",
        "    Returns:\n",
        "      Transformers models based on hyperparameters\n",
        "  \"\"\"\n",
        "  encoders = Encoders(d_model, n_layers, n_heads, d_ffn, dropout)\n",
        "  decoders = Decoders(len(trg_vocab), d_model, n_layers, n_heads, d_ffn, dropout)\n",
        "  pos_enc_src = PositionalEncodings(d_model, dropout, max_length)\n",
        "  pos_enc_trg = PositionalEncodings(d_model, dropout, max_length)\n",
        "\n",
        "  src_embeds = nn.Sequential(Embeddingss(len(src_vocab), d_model), pos_enc_src)\n",
        "  trg_embeds = nn.Sequential(Embeddingss(len(trg_vocab), d_model), pos_enc_trg)\n",
        "\n",
        "\n",
        "  # create the Transformers models\n",
        "  models = Transformers(encoders, decoders, src_embeds, trg_embeds,\n",
        "                    src_pad_idx = src_vocab['<pad>'],\n",
        "                    trg_pad_idx = trg_vocab['<pad>'],\n",
        "                    device = device)\n",
        "\n",
        "   # initialize parameters with Xavier/Glorot\n",
        "  for p in models.parameters():\n",
        "    if p.dim() > 1:\n",
        "      nn.init.xavier_uniform_(p)\n",
        "\n",
        "  # models.to(devices)\n",
        "  return models"
      ],
      "metadata": {
        "id": "jWSnK2bLpgVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open(\"/content/drive/MyDrive/eng-tel.txt\", 'r', encoding='utf-8') as file:\n",
        "  raws = []\n",
        "  n = 0\n",
        "  for line in file:\n",
        "    n +=1\n",
        "    if n==5:\n",
        "      break\n",
        "    telugu_sentence, english_sentence = line.strip().split('>>')\n",
        "    raws.append((telugu_sentence, english_sentence))\n",
        "\n",
        "print(raws)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecQBeOKfpo60",
        "outputId": "97c44240-dc1d-44e7-d909-e3099209a507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('A suspicious activity alert is a notification from your bank about unusual transactions or account activity that may indicate fraud. ', ' మీ బ్యాంక్ నుండి అపరిపూర్ణ లావాదేవీలు లేదా ఖాతా చర్యలు మోసం సూచించేలా ఉన్నప్పుడు అందించే హెచ్చరిక.'), ('You received a suspicious activity alert because your bank detected unusual transactions or login attempts that differ from your normal banking behavior. ', ' మీ బ్యాంక్ సాధారణ బ్యాంకింగ్ ప్రవర్తన నుండి భిన్నంగా ఉన్న లావాదేవీలు లేదా లాగిన్ ప్రయత్నాలను కనుగొని, మీకు అనుమానాస్పద కార్యకలాప హెచ్చరిక పంపింది.'), ('If you receive a suspicious activity alert, review the transaction details, confirm whether it was authorized, and contact your bank immediately if it was unauthorized. ', ' మీరు అనుమానాస్పద కార్యకలాప హెచ్చరిక పొందితే, లావాదేవీ వివరాలను సమీక్షించండి, అది అనుమతించబడిందా లేదా నిర్ధారించుకోండి, అనుమతించబడనిదైతే వెంటనే మీ బ్యాంకును సంప్రదించండి.'), ('You can report a suspicious transaction by calling your bank’s customer service, visiting a branch, or using the fraud reporting feature in online banking. ', ' మీరు అనుమానాస్పద లావాదేవీని మీ బ్యాంక్ కస్టమర్ సేవను కాల్ చేయడం ద్వారా, బ్రాంచ్\\u200cకు వెళ్లడం ద్వారా లేదా ఆన్\\u200cలైన్ బ్యాంకింగ్\\u200cలో మోసం నివేదించే ఫీచర్\\u200cను ఉపయోగించడం ద్వారా నివేదించవచ్చు.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "models = make_models(device, vocab_src, vocab_trg,\n",
        "                   n_layers=3, n_heads=8, d_model=256,\n",
        "                   d_ffn=512, max_length=150)\n",
        "\n",
        "models.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP3Y9MzkprHW",
        "outputId": "95cd1d5f-aaaf-4203-e9a9-9bed15982318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformers(\n",
              "  (encoders): Encoders(\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x EncoderLayers(\n",
              "        (attention): MultiHeadAttentions(\n",
              "          (Wq): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wk): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wv): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wo): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (positionwise_fnn): PositionwiseFeedForwards(\n",
              "          (linear_layer_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (linear_layer_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (fnn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoders): Decoders(\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x DecoderLayers(\n",
              "        (masked_attention): MultiHeadAttentions(\n",
              "          (Wq): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wk): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wv): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wo): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (masked_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (attention): MultiHeadAttentions(\n",
              "          (Wq): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wk): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wv): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wo): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (positionwise_fnn): PositionwiseFeedForwards(\n",
              "          (linear_layer_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (linear_layer_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (fnn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (Wo): Linear(in_features=256, out_features=11960, bias=True)\n",
              "  )\n",
              "  (src_embeds): Sequential(\n",
              "    (0): Embeddingss(\n",
              "      (lut): Embedding(11933, 256)\n",
              "    )\n",
              "    (1): PositionalEncodings(\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (trg_embeds): Sequential(\n",
              "    (0): Embeddingss(\n",
              "      (lut): Embedding(11960, 256)\n",
              "    )\n",
              "    (1): PositionalEncodings(\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(models):\n",
        "    return sum(p.numel() for p in models.parameters() if p.requires_grad)\n",
        "\n",
        "# Now you can count the parameters\n",
        "print(f'The models has {count_parameters(models):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQvvAD37pt9p",
        "outputId": "c1ce5778-846f-46df-a7c1-714c9c23890c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The models has 13,143,992 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATEs = 0.0005\n",
        "\n",
        "optimizers = torch.optim.Adam(models.parameters(), lr = LEARNING_RATEs)\n",
        "criterions = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
      ],
      "metadata": {
        "id": "wGf9kq1zp3W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trains(models, iterator, optimizers, criterions, clip):\n",
        "\n",
        "  # set the models to training mode\n",
        "  models.train()\n",
        "\n",
        "  epoch_losss = 0\n",
        "\n",
        "  # loop through each batch in the iterator\n",
        "  for i, batch in enumerate(iterator):\n",
        "\n",
        "    # set the source and target batches\n",
        "    srcs,trgs = batch\n",
        "\n",
        "    # Move srcs and trgs to the same devices as the models\n",
        "    srcs = srcs.to(device)\n",
        "    trgs = trgs.to(device)\n",
        "\n",
        "    # zero the gradients\n",
        "    optimizers.zero_grad()\n",
        "\n",
        "    # logitss for each outputs\n",
        "    logitss = models(srcs, trgs[:,:-1])\n",
        "\n",
        "    # expected outputs\n",
        "    expected_outputs = trgs[:,1:]\n",
        "\n",
        "    criterions.ignore_index = models.trg_pad_idx\n",
        "\n",
        "    # logitss = logitss.to(models.devices)\n",
        "    # expected_outputs = expected_outputs.to(models.devices)\n",
        "\n",
        "    # calculate the losss\n",
        "    losss = criterions(logitss.contiguous().view(-1, logitss.shape[-1]),\n",
        "                    expected_outputs.contiguous().view(-1))\n",
        "\n",
        "    # backpropagation\n",
        "    losss.backward()\n",
        "\n",
        "    # clip the weights\n",
        "    torch.nn.utils.clip_grad_norm_(models.parameters(), clip)\n",
        "\n",
        "    # update the weights\n",
        "    optimizers.step()\n",
        "\n",
        "    # update the losss\n",
        "    epoch_losss += losss.item()\n",
        "\n",
        "  # return the average losss for the epoch\n",
        "  return epoch_losss / len(iterator)"
      ],
      "metadata": {
        "id": "H5WZey4Jp5_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluates(models, iterator, criterions):\n",
        "\n",
        "  # set the models to evaluation mode\n",
        "  models.eval()\n",
        "\n",
        "  epoch_losss = 0\n",
        "\n",
        "  # evaluates without updating gradients\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # loop through each batch in the iterator\n",
        "    for i, batch in enumerate(iterator):\n",
        "\n",
        "      # set the source and target batches\n",
        "      srcs, trgs = batch\n",
        "\n",
        "      # Move srcs and trgs to the same devices as the models\n",
        "      # srcs = srcs.to(models.devices)\n",
        "      # trgs = trgs.to(models.devices)\n",
        "\n",
        "\n",
        "      # logitss for each outputs\n",
        "      logitss = models(srcs, trgs[:,:-1])\n",
        "\n",
        "      # expected outputs\n",
        "      expected_outputs = trgs[:,1:]\n",
        "\n",
        "      # calculate the losss\n",
        "      losss = criterions(logitss.contiguous().view(-1, logitss.shape[-1]),\n",
        "                      expected_outputs.contiguous().view(-1))\n",
        "\n",
        "      # update the losss\n",
        "      epoch_losss += losss.item()\n",
        "\n",
        "  # return the average losss for the epoch\n",
        "  return epoch_losss / len(iterator)"
      ],
      "metadata": {
        "id": "Yuaqw8w0qFO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "\n",
        "# Print GPU name\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sDm9KihqcS7",
        "outputId": "0cb1bd31-2084-411c-9fb3-5d8d1ea0c255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: True\n",
            "GPU: Tesla T4\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_times(start_times, end_times):\n",
        "  elapsed_times = end_times - start_times\n",
        "  elapsed_minss = int(elapsed_times / 60)\n",
        "  elapsed_secss = int(elapsed_times - (elapsed_minss * 60))\n",
        "  return elapsed_minss, elapsed_secss"
      ],
      "metadata": {
        "id": "A1VE1nYiqe0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi8ue7hcqkSB",
        "outputId": "4f772486-78e2-4a32-d086-ab7c47c29485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May  5 09:35:21 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P0             35W /   70W |     326MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "\n",
        "# Training settings\n",
        "N_EPOCHSs = 10\n",
        "CLIPs = 1\n",
        "\n",
        "# ✅ Google Drive paths\n",
        "best_model_path = '/content/drive/MyDrive/transformer-model_tel.pt'\n",
        "checkpoint_dir = '/content/drive/MyDrive/checkpoints'\n",
        "checkpoint_path = os.path.join(checkpoint_dir, 'transformer-model_tel_checkpoint.pt')\n",
        "\n",
        "# Create checkpoints directory if it doesn't exist\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Initialize defaults\n",
        "start_epoch = 0\n",
        "best_valid_losss = float('inf')\n",
        "\n",
        "# ✅ Try to resume from checkpoints\n",
        "if os.path.exists(checkpoint_path):\n",
        "    checkpoints = torch.load(checkpoint_path, map_location=device)  # or use your devices\n",
        "\n",
        "    models.load_state_dict(checkpoints['model_state_dict'])\n",
        "    optimizers.load_state_dict(checkpoints['optimizer_state_dict'])\n",
        "    start_epoch = checkpoints['epoch'] + 1\n",
        "    best_valid_losss = checkpoints['valid_losss']\n",
        "    print(f\"✅ Resumed from checkpoints at epoch {start_epoch}\")\n",
        "\n",
        "# ✅ Utility to time epochs\n",
        "def epoch_times(start_times, end_times):\n",
        "    elapsed = end_times - start_times\n",
        "    return int(elapsed // 60), int(elapsed % 60)\n",
        "\n",
        "# ✅ Training loop\n",
        "for epoch in range(start_epoch, N_EPOCHSs):\n",
        "    start_times = time.time()\n",
        "\n",
        "    train_losss = trains(models, train_iters, optimizers, criterions, CLIPs)\n",
        "    valid_losss = evaluates(models, valid_iters, criterions)\n",
        "\n",
        "    end_times = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_times(start_times, end_times)\n",
        "\n",
        "    # ✅ Save best models to Drive\n",
        "    if valid_losss < best_valid_losss:\n",
        "        best_valid_losss = valid_losss\n",
        "        torch.save(models.state_dict(), best_model_path)\n",
        "        print(f\"💾 Saved new best models to: {best_model_path}\")\n",
        "\n",
        "    # ✅ Save checkpoints to Drive\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': models.state_dict(),\n",
        "        'optimizer_state_dict': optimizers.state_dict(),\n",
        "        'valid_losss': valid_losss,\n",
        "    }, checkpoint_path)\n",
        "\n",
        "    print(f'\\n📘 Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_losss:.3f} | Train PPL: {math.exp(train_losss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_losss:.3f} |  Val. PPL: {math.exp(valid_losss):7.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwuI9ey2qmYD",
        "outputId": "528964db-7ea7-4dac-f36a-bab3f689f207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Saved new best models to: /content/drive/MyDrive/transformer-model_tel.pt\n",
            "\n",
            "📘 Epoch: 01 | Time: 4m 40s\n",
            "\tTrain Loss: 0.944 | Train PPL:   2.571\n",
            "\t Val. Loss: 0.669 |  Val. PPL:   1.952\n",
            "💾 Saved new best models to: /content/drive/MyDrive/transformer-model_tel.pt\n",
            "\n",
            "📘 Epoch: 02 | Time: 4m 40s\n",
            "\tTrain Loss: 0.622 | Train PPL:   1.862\n",
            "\t Val. Loss: 0.530 |  Val. PPL:   1.699\n",
            "💾 Saved new best models to: /content/drive/MyDrive/transformer-model_tel.pt\n",
            "\n",
            "📘 Epoch: 03 | Time: 4m 39s\n",
            "\tTrain Loss: 0.481 | Train PPL:   1.618\n",
            "\t Val. Loss: 0.471 |  Val. PPL:   1.601\n",
            "💾 Saved new best models to: /content/drive/MyDrive/transformer-model_tel.pt\n",
            "\n",
            "📘 Epoch: 04 | Time: 4m 39s\n",
            "\tTrain Loss: 0.400 | Train PPL:   1.492\n",
            "\t Val. Loss: 0.429 |  Val. PPL:   1.536\n",
            "💾 Saved new best models to: /content/drive/MyDrive/transformer-model_tel.pt\n",
            "\n",
            "📘 Epoch: 05 | Time: 4m 39s\n",
            "\tTrain Loss: 0.347 | Train PPL:   1.414\n",
            "\t Val. Loss: 0.409 |  Val. PPL:   1.505\n",
            "💾 Saved new best models to: /content/drive/MyDrive/transformer-model_tel.pt\n",
            "\n",
            "📘 Epoch: 06 | Time: 4m 39s\n",
            "\tTrain Loss: 0.308 | Train PPL:   1.361\n",
            "\t Val. Loss: 0.391 |  Val. PPL:   1.478\n",
            "💾 Saved new best models to: /content/drive/MyDrive/transformer-model_tel.pt\n",
            "\n",
            "📘 Epoch: 07 | Time: 4m 39s\n",
            "\tTrain Loss: 0.279 | Train PPL:   1.321\n",
            "\t Val. Loss: 0.380 |  Val. PPL:   1.463\n",
            "💾 Saved new best models to: /content/drive/MyDrive/transformer-model_tel.pt\n",
            "\n",
            "📘 Epoch: 08 | Time: 4m 40s\n",
            "\tTrain Loss: 0.258 | Train PPL:   1.294\n",
            "\t Val. Loss: 0.373 |  Val. PPL:   1.451\n",
            "\n",
            "📘 Epoch: 09 | Time: 4m 40s\n",
            "\tTrain Loss: 0.238 | Train PPL:   1.269\n",
            "\t Val. Loss: 0.378 |  Val. PPL:   1.459\n",
            "💾 Saved new best models to: /content/drive/MyDrive/transformer-model_tel.pt\n",
            "\n",
            "📘 Epoch: 10 | Time: 4m 40s\n",
            "\tTrain Loss: 0.223 | Train PPL:   1.250\n",
            "\t Val. Loss: 0.370 |  Val. PPL:   1.448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best models (only the state_dict, not a full checkpoints)\n",
        "models.load_state_dict(torch.load('/content/drive/MyDrive/transformer-model_tel.pt', map_location=devices))\n",
        "models.to(device)  # Make sure models is on the correct devices\n",
        "models.eval()      # Set models to evaluation mode\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_losss = evaluates(models, test_iters, criterions)\n",
        "\n",
        "print(f'Test Loss: {test_losss:.3f} | Test PPL: {math.exp(test_losss):7.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhZAd_DX-6Lk",
        "outputId": "74cfeb45-1984-4eac-f6d3-90e604cedd43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.360 | Test PPL:   1.433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best models (just state_dict)\n",
        "import os\n",
        "\n",
        "file_paths = '/content/drive/MyDrive/transformer-model_tel.pt'  # Path to saved models state_dict\n",
        "\n",
        "if os.path.exists(file_paths):\n",
        "    models.load_state_dict(torch.load(file_paths, map_location=device))\n",
        "    models.to(device)\n",
        "    models.eval()\n",
        "    print(\"✅ Best models loaded successfully.\")\n",
        "else:\n",
        "    print(f\"❌ Error: File not found at {file_paths}. Please check the path.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx_2Fc-0--Uo",
        "outputId": "9e1c977a-db60-4f74-fd0e-ec23d335325e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Best models loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.save({\n",
        "    'model_state_dict': models.state_dict(),\n",
        "    'optimizer_state_dict': optimizers.state_dict(),\n",
        "    'epoch': epoch,\n",
        "    'valid_losss': valid_losss\n",
        "}, '/content/drive/MyDrive/checkpoints/transformer-model_tel_checkpoint.pt')\n"
      ],
      "metadata": {
        "id": "HEKqhOQn_NTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load full checkpoints (models + optimizers + metadata)\n",
        "import os\n",
        "\n",
        "checkpoint_path = '/content/drive/MyDrive/checkpoints/transformer-model_tel_checkpoint.pt'\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    checkpoints = torch.load(checkpoint_path, map_location=device)\n",
        "    models.load_state_dict(checkpoints['model_state_dict'])\n",
        "    optimizers.load_state_dict(checkpoints['optimizer_state_dict'])  # Optional if resuming training\n",
        "    start_epoch = checkpoints['epoch'] + 1\n",
        "    best_valid_losss = checkpoints['valid_losss']\n",
        "    models.to(device)\n",
        "    models.eval()\n",
        "    print(f\"✅ Checkpoint loaded. Resuming from epoch {start_epoch}\")\n",
        "else:\n",
        "    print(f\"❌ Error: Checkpoint not found at {checkpoint_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIFVYkQZ_QCY",
        "outputId": "610cc477-84c9-4db5-d8e6-ba5d8529bdc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Checkpoint loaded. Resuming from epoch 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "models.load_state_dict(torch.load('/content/drive/MyDrive/transformer-model_tel.pt'))\n",
        "\n",
        "# calculate the losss on the test set\n",
        "test_losss = evaluates(models, test_iters, criterions)\n",
        "\n",
        "print(f'Test Loss: {test_losss:.3f} | Test PPL: {math.exp(test_losss):7.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buyNRI9L_XwT",
        "outputId": "2c475354-ad92-4124-8cf3-36d7cfc9fe18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.361 | Test PPL:   1.434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models.load_state_dict(torch.load('/content/drive/MyDrive/transformer-model_tel.pt', map_location=devices))\n",
        "models.to(device)\n",
        "models.eval()\n",
        "print(\"✅ Model state_dict loaded successfully from best models file.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PP-H5er_eUc",
        "outputId": "2e6005bc-b12a-44ba-8ce9-28225bbd486d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model state_dict loaded successfully from best models file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_paths = '/content/drive/MyDrive/transformer-model_tel.pt'  # Path to models state_dict\n",
        "\n",
        "if os.path.exists(file_paths):\n",
        "    models.load_state_dict(torch.load(file_paths, map_location=devices))\n",
        "    models.to(devices)\n",
        "    models.eval()\n",
        "    print(\"✅ Loaded models state_dict successfully.\")\n",
        "else:\n",
        "    print(f\"❌ Error: File not found at {file_paths}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEJhT9yr_qNh",
        "outputId": "694897d9-7969-445c-c159-175ef2fbb84a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded models state_dict successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "torch.save(models.state_dict(), '/content/drive/MyDrive/transformer2_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhUx3BQL_4zW",
        "outputId": "003999db-26a6-4b44-855e-27696e8ffaba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "models.load_state_dict(torch.load('/content/drive/MyDrive/transformer2_model.pth'))\n",
        "models.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbaI6FiF_6LP",
        "outputId": "6e661f8f-fb2e-4fa4-f31b-6b822d12f74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformers(\n",
              "  (encoders): Encoders(\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x EncoderLayers(\n",
              "        (attention): MultiHeadAttentions(\n",
              "          (Wq): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wk): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wv): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wo): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (positionwise_fnn): PositionwiseFeedForwards(\n",
              "          (linear_layer_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (linear_layer_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (fnn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoders): Decoders(\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x DecoderLayers(\n",
              "        (masked_attention): MultiHeadAttentions(\n",
              "          (Wq): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wk): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wv): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wo): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (masked_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (attention): MultiHeadAttentions(\n",
              "          (Wq): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wk): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wv): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (Wo): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (positionwise_fnn): PositionwiseFeedForwards(\n",
              "          (linear_layer_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (linear_layer_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (fnn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (Wo): Linear(in_features=256, out_features=11960, bias=True)\n",
              "  )\n",
              "  (src_embeds): Sequential(\n",
              "    (0): Embeddingss(\n",
              "      (lut): Embedding(11933, 256)\n",
              "    )\n",
              "    (1): PositionalEncodings(\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (trg_embeds): Sequential(\n",
              "    (0): Embeddingss(\n",
              "      (lut): Embedding(11960, 256)\n",
              "    )\n",
              "    (1): PositionalEncodings(\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_multiline(text, models, devices, vocab_src, vocab_trg, tokenizer_te, max_length=150):\n",
        "    lines = text.strip().split('\\n')  # Split the input text into individual lines\n",
        "    all_translations = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            srcs, trg_tokenss = translate_sentence(line.strip(), models, devices, vocab_src, vocab_trg, tokenizer_te, max_length)\n",
        "            translated_line = \" \".join(trg_tokenss)\n",
        "            all_translations.append(translated_line)\n",
        "\n",
        "            # Optional: print source and target for each line\n",
        "            print(f\"source --> {' '.join(srcs[1:-1])}\")  # remove <bos> and <eos>\n",
        "            print(f\"target translation --> {translated_line}\\n\")\n",
        "\n",
        "    return \"\\n\".join(all_translations)\n"
      ],
      "metadata": {
        "id": "y6-JjLCDAF69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "def translate_sentence(sentence, models, devices, vocab_src, vocab_trg, tokenizer_te, max_length=150):\n",
        "    models.eval()\n",
        "\n",
        "    # Check if the input is a string and tokenize accordingly\n",
        "\n",
        "    if isinstance(sentence, str):\n",
        "        # Tokenize the sentence using the Telugu tokenizer\n",
        "        tokenss = tokenizer_te(sentence)\n",
        "        srcs = ['<bos>'] + [token.text.lower() for token in tokenss] + ['<eos>']\n",
        "    else:\n",
        "        srcs = ['<bos>'] + sentence + ['<eos>']\n",
        "\n",
        "    # Map the tokenss to their respective indices in the source vocabulary\n",
        "    src_indexess = [vocab_src[token] if token in vocab_src else vocab_src['<unk>'] for token in srcs]\n",
        "\n",
        "    # Convert the list of indices to a tensor and add a batch dimension\n",
        "    src_tensors = torch.tensor(src_indexess, dtype=torch.long).unsqueeze(0).to(devices)\n",
        "\n",
        "    # Initialize the list of target indices with the index of ''\n",
        "    trg_indexess = [vocab_trg['<bos>']]\n",
        "\n",
        "    # Initialize the loop to generate tokenss up to a maximum length\n",
        "    for i in range(max_length):\n",
        "        # Convert the current list of target indices to a tensor and add a batch dimension\n",
        "        trg_tensors = torch.tensor(trg_indexess, dtype=torch.long).unsqueeze(0).to(devices)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Feed the source and target tensors to the models to get the logitss\n",
        "            outputs = models(src_tensors, trg_tensors)\n",
        "            pred_tokens = outputs.argmax(2)[:, -1].item()\n",
        "\n",
        "            # Check if the predicted token is '' or the maximum length is reached\n",
        "            if pred_tokens == vocab_trg['<eos>'] or i == (max_length - 1):\n",
        "                # Convert indices to tokenss\n",
        "                trg_tokenss = [vocab_trg.lookup_token(index) for index in trg_indexess[1:]]  # Skip ''\n",
        "                return srcs, trg_tokenss\n",
        "\n",
        "            # Append the predicted token to the list of target indices\n",
        "            trg_indexess.append(pred_tokens)\n",
        "\n",
        "\n",
        "src_text = \"how was it?\"\n",
        "models = models  # Replace with your actual models\n",
        "devices = 'cuda' if torch.cuda.is_available() else 'cpu'  # Assuming CUDA is available and appropriate\n",
        "srcs, trg_tokenss = translate_sentence(src_text, models, devices, vocab_src, vocab_trg, tokenizer_te)\n",
        "print(f'source --> {\" \".join(srcs[1:-1])}')\n",
        "print(f'target translation --> {\" \".join(trg_tokenss)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOFfYWgzAJnO",
        "outputId": "93b3c832-7fcc-4a63-e682-10e72f897c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source --> how was it ?\n",
            "target translation -->   ఎలా <unk> ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_text = \"absolutely ! i ' m sorry to hear that you ' re having trouble blocking your card . i ' m here to assist you with that . to block your card , please follow these steps 1 . contact our customer support team at {{customer support phone number}} or visit our website at {{company website url}} . 2 . provide them with the necessary details , such as your card number , expiration date , and any other required information , and any additional information , and any other relevant information  expiration date of the card\"\n",
        "models = models  # Replace with your actual models\n",
        "devices = 'cuda' if torch.cuda.is_available() else 'cpu'  # Assuming CUDA is available and appropriate\n",
        "srcs, trg_tokenss = translate_sentence(src_text, models, devices, vocab_src, vocab_trg, tokenizer_te)\n",
        "print(f'source --> {\" \".join(srcs[1:-1])}')\n",
        "print(f'target translation --> {\" \".join(trg_tokenss)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fY6hq8-ALw5",
        "outputId": "a73551a3-e44b-49f7-cb7e-b04e743c7780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source --> absolutely ! i ' m sorry to hear that you ' re having trouble blocking your card . i ' m here to assist you with that . to block your card , please follow these steps 1 . contact our customer support team at { { customer support phone number } } or visit our website at { { company website url } } . 2 . provide them with the necessary details , such as your card number , expiration date , and any other required information , and any additional information , and any other relevant information   expiration date of the card\n",
            "target translation -->   ఖచ్చితంగా ! మీ కార్డును తిరిగి పొందడంలో మీరు ఎదుర్కొన్న ఏ ఇతర సంబంధిత సమాచారం అయినా , మీ కార్డును తిరిగి పొందడంలో మీకు సహాయం చేయడానికి మేము చేయగలిగినదంతా చేస్తాము . మీ కార్డును నిరోధించడానికి , దయచేసి ఈ దశలను అనుసరించండి :\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiline_input = \"\"\"\n",
        "absolutely ! i ' m sorry to hear that you ' re having trouble blocking your card .\n",
        " i ' m here to assist you with that .\n",
        " to block your card , please follow these steps\n",
        "  1 . contact our customer support team at {{customer support phone number}} or visit our website at {{company website url}} .\n",
        "  2 . provide them with the necessary details , such as your card number , expiration date , any other required information , any additional information , expiration date of the card.\n",
        "\"\"\"\n",
        "\n",
        "translated_text = translate_multiline(multiline_input, models, devices, vocab_src, vocab_trg, tokenizer_te)\n",
        "print(\"Full Translation:\\n\", translated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBWJABJrAO6k",
        "outputId": "872694d4-6960-4552-f14d-110c7e688ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source --> absolutely ! i ' m sorry to hear that you ' re having trouble blocking your card .\n",
            "target translation -->   ఖచ్చితంగా ! మీ కార్డును తిరిగి పొందడంలో మీరు ఎదుర్కొన్న బ్యాంక్ మేము మిమ్మల్ని <unk> ద్వారా నవీకరిస్తాము .\n",
            "\n",
            "source --> i ' m here to assist you with that .\n",
            "target translation -->   దానికి మీకు సహాయం చేయడానికి మేము ఇక్కడ ఉన్నాము .\n",
            "\n",
            "source --> to block your card , please follow these steps\n",
            "target translation -->   మీ కార్డును నిరోధించడానికి , దయచేసి ఈ దశలను అనుసరించండి :\n",
            "\n",
            "source --> 1 . contact our customer support team at { { customer support phone number } } or visit our website at { { company website url } } .\n",
            "target translation -->   1 . { { కస్టమర్ సపోర్ట్ ఫోన్ నంబర్ } at వద్ద మా కస్టమర్ మద్దతు బృందాన్ని సంప్రదించండి లేదా { { కంపెనీ వెబ్‌సైట్ url } at వద్ద మా వెబ్‌సైట్‌ను సందర్శించండి .\n",
            "\n",
            "source --> 2 . provide them with the necessary details , such as your card number , expiration date , any other required information , any additional information , expiration date of the card .\n",
            "target translation -->   2 . మీ కార్డ్ నంబర్ , గడువు తేదీ , అవసరమైన ఇతర సమాచారం వంటి అవసరమైన వివరాలను వారికి అందించండి , అది కార్డు యొక్క తేదీ , మొత్తం .\n",
            "\n",
            "Full Translation:\n",
            "   ఖచ్చితంగా ! మీ కార్డును తిరిగి పొందడంలో మీరు ఎదుర్కొన్న బ్యాంక్ మేము మిమ్మల్ని <unk> ద్వారా నవీకరిస్తాము .\n",
            "  దానికి మీకు సహాయం చేయడానికి మేము ఇక్కడ ఉన్నాము .\n",
            "  మీ కార్డును నిరోధించడానికి , దయచేసి ఈ దశలను అనుసరించండి :\n",
            "  1 . { { కస్టమర్ సపోర్ట్ ఫోన్ నంబర్ } at వద్ద మా కస్టమర్ మద్దతు బృందాన్ని సంప్రదించండి లేదా { { కంపెనీ వెబ్‌సైట్ url } at వద్ద మా వెబ్‌సైట్‌ను సందర్శించండి .\n",
            "  2 . మీ కార్డ్ నంబర్ , గడువు తేదీ , అవసరమైన ఇతర సమాచారం వంటి అవసరమైన వివరాలను వారికి అందించండి , అది కార్డు యొక్క తేదీ , మొత్తం .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiline_input = \"\"\"\n",
        "I'm here to assist you in finding the nearest ATM in your area. To help me provide accurate information.\n",
        "i ' ll be glad to assist you with that . to initiate the dispute process , please follow these steps.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "translated_text = translate_multiline(multiline_input, models, devices, vocab_src, vocab_trg, tokenizer_te)\n",
        "print(\"Full Translation:\\n\", translated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptUbJEy8ASms",
        "outputId": "3f03e5aa-c3b1-4b0f-d4d9-38663c8f786f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source --> i'm here to assist you in finding the nearest atm in your area . to help me provide accurate information .\n",
            "target translation -->   మీ ప్రాంతంలో సమీప <unk> కనుగొనడంలో మీకు సహాయం చేయడానికి నేను ఇక్కడ ఉన్నాను . ఖచ్చితమైన సమాచారాన్ని అందించడంలో నాకు సహాయపడటానికి నేను ఇక్కడ ఉన్నాను .\n",
            "\n",
            "source --> i ' ll be glad to assist you with that . to initiate the dispute process , please follow these steps .\n",
            "target translation -->   నేను మీకు సహాయం చేయడానికి సంతోషిస్తాను . వివాద ప్రక్రియను ప్రారంభించడానికి , దయచేసి ఈ దశలను అనుసరించండి :\n",
            "\n",
            "Full Translation:\n",
            "   మీ ప్రాంతంలో సమీప <unk> కనుగొనడంలో మీకు సహాయం చేయడానికి నేను ఇక్కడ ఉన్నాను . ఖచ్చితమైన సమాచారాన్ని అందించడంలో నాకు సహాయపడటానికి నేను ఇక్కడ ఉన్నాను .\n",
            "  నేను మీకు సహాయం చేయడానికి సంతోషిస్తాను . వివాద ప్రక్రియను ప్రారంభించడానికి , దయచేసి ఈ దశలను అనుసరించండి :\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiline_input = \"\"\"\n",
        "absolutely ! i ' m here to assist you with activating your credit card for international usage .\n",
        "to get started , please follow these\n",
        " steps 1 . contact our customer support team at {{customer support phone number}} or visit our website at {{company website url}} .\n",
        "  2 . provide them with your credit card details , such as the card number , expiration date , and security code .\n",
        "  3 . they will guide you through the necessary information , and any additional information , and any specific instructions on the necessary information and credit card details , and any additional information will be able to ensure that you can also may need to ensure that you can usually located in the necessary information can guide you should be required information required information about the necessary information about the necessary details of the necessary information\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "translated_text = translate_multiline(multiline_input, models, devices, vocab_src, vocab_trg, tokenizer_te)\n",
        "print(\"Full Translation:\\n\", translated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yft_Qe2VAWJj",
        "outputId": "65238844-5d6d-4e4d-a365-5da4eba233a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source --> absolutely ! i ' m here to assist you with activating your credit card for international usage .\n",
            "target translation -->   ఖచ్చితంగా ! అంతర్జాతీయ వినియోగం కోసం మీ క్రెడిట్ కార్డును సక్రియం చేయడంలో మీకు సహాయం చేయడానికి నేను ఇక్కడ ఉంటాను .\n",
            "\n",
            "source --> to get started , please follow these\n",
            "target translation -->   ప్రారంభించడానికి , దయచేసి ఈ దశలను అనుసరించండి :\n",
            "\n",
            "source --> steps 1 . contact our customer support team at { { customer support phone number } } or visit our website at { { company website url } } .\n",
            "target translation -->   1 . { { కస్టమర్ సపోర్ట్ ఫోన్ నంబర్ } at వద్ద మా కస్టమర్ మద్దతు బృందాన్ని సంప్రదించండి లేదా { { కంపెనీ వెబ్‌సైట్ url } at వద్ద మా వెబ్‌సైట్‌ను సందర్శించండి .\n",
            "\n",
            "source --> 2 . provide them with your credit card details , such as the card number , expiration date , and security code .\n",
            "target translation -->   2 . కార్డ్ నంబర్ , గడువు తేదీ మరియు భద్రతా కోడ్ వంటి మీ క్రెడిట్ కార్డ్ వివరాలను వారికి అందించండి .\n",
            "\n",
            "source --> 3 . they will guide you through the necessary information , and any additional information , and any specific instructions on the necessary information and credit card details , and any additional information will be able to ensure that you can also may need to ensure that you can usually located in the necessary information can guide you should be required information required information about the necessary information about the necessary details of the necessary information\n",
            "target translation -->   3 . వారు మీకు అవసరమైన సమాచారం , మరియు అవసరమైన అదనపు సమాచారం మరియు క్రెడిట్ కార్డ్ వివరాలు మరియు ఏదైనా అదనపు సమాచారం ఆధారంగా , మీరు సాధారణంగా అవసరమైన సమాచారం గురించి అవసరమైన సమాచారం మరియు ఏదైనా అదనపు సమాచారం గురించి అవసరమైన సమాచారాన్ని కూడా వారు మీకు ఇవ్వగలుగుతాను .\n",
            "\n",
            "Full Translation:\n",
            "   ఖచ్చితంగా ! అంతర్జాతీయ వినియోగం కోసం మీ క్రెడిట్ కార్డును సక్రియం చేయడంలో మీకు సహాయం చేయడానికి నేను ఇక్కడ ఉంటాను .\n",
            "  ప్రారంభించడానికి , దయచేసి ఈ దశలను అనుసరించండి :\n",
            "  1 . { { కస్టమర్ సపోర్ట్ ఫోన్ నంబర్ } at వద్ద మా కస్టమర్ మద్దతు బృందాన్ని సంప్రదించండి లేదా { { కంపెనీ వెబ్‌సైట్ url } at వద్ద మా వెబ్‌సైట్‌ను సందర్శించండి .\n",
            "  2 . కార్డ్ నంబర్ , గడువు తేదీ మరియు భద్రతా కోడ్ వంటి మీ క్రెడిట్ కార్డ్ వివరాలను వారికి అందించండి .\n",
            "  3 . వారు మీకు అవసరమైన సమాచారం , మరియు అవసరమైన అదనపు సమాచారం మరియు క్రెడిట్ కార్డ్ వివరాలు మరియు ఏదైనా అదనపు సమాచారం ఆధారంగా , మీరు సాధారణంగా అవసరమైన సమాచారం గురించి అవసరమైన సమాచారం మరియు ఏదైనా అదనపు సమాచారం గురించి అవసరమైన సమాచారాన్ని కూడా వారు మీకు ఇవ్వగలుగుతాను .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiline_input = \"\"\"\n",
        "Sure! I' m here to assist you with activating your card for international usage.\n",
        " Here' s what you need to do\n",
        " 1. Contact our customer support team at {{customer support phone number}} or visit our website at {{company website url}} to initiate the card cancellation process.\n",
        " 2. Provide the necessary details, such as your card number, card number, and other necessary information for, and any additional information.\n",
        " 3. If you may be able to verify if you' ll be prepared to provide any specific card details like card details, expiration date, expiration to complete and any other required information, i' re looking for any additional information, i can vary depending on card details, card details.\n",
        " Once i' re traveling abroad, the card details, expiration date,\n",
        "\"\"\"\n",
        "\n",
        "translated_text = translate_multiline(multiline_input, models, devices, vocab_src, vocab_trg, tokenizer_te)\n",
        "print(\"Full Translation:\\n\", translated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwKg_wLMAYLt",
        "outputId": "6a47dcef-311a-452e-b69e-ea3e63b4c060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source --> sure ! i ' m here to assist you with activating your card for international usage .\n",
            "target translation -->   ఖచ్చితంగా ! అంతర్జాతీయ వినియోగం కోసం మీ కార్డును సక్రియం చేయడంలో మీకు సహాయం చేయడానికి నేను ఇక్కడ ఉంటాను .\n",
            "\n",
            "source --> here ' s what you need to do\n",
            "target translation -->   మీరు ఏమి చేయాలో ఇక్కడ ఉంది :\n",
            "\n",
            "source --> 1 . contact our customer support team at { { customer support phone number } } or visit our website at { { company website url } } to initiate the card cancellation process .\n",
            "target translation -->   1 . { { కస్టమర్ సపోర్ట్ ఫోన్ నంబర్ } at వద్ద మా కస్టమర్ మద్దతు బృందాన్ని సంప్రదించండి లేదా కార్డ్ రద్దు ప్రక్రియను ప్రారంభించడానికి మా వెబ్‌సైట్‌ను { { కంపెనీ వెబ్‌సైట్ url } వద్ద సందర్శించండి .\n",
            "\n",
            "source --> 2 . provide the necessary details , such as your card number , card number , and other necessary information for , and any additional information .\n",
            "target translation -->   2 . మీ కార్డ్ నంబర్ , కార్డ్ నంబర్ మరియు ఏదైనా అదనపు సమాచారం వంటి అవసరమైన వివరాలను అందించండి .\n",
            "\n",
            "source --> 3 . if you may be able to verify if you ' ll be prepared to provide any specific card details like card details , expiration date , expiration to complete and any other required information , i ' re looking for any additional information , i can vary depending on card details , card details .\n",
            "target translation -->   3 . మీరు ఇంతకు ముందు ఉపయోగించని తర్వాత , కార్డ్ వివరాలు , గడువు తేదీ మరియు అవసరమైన ఇతర సమాచారం వంటి నిర్దిష్ట కార్డ్ వివరాలను అందించమని మీరు అధికారం ఇవ్వాలి , అది అందించే ఇతర సమాచారం కోసం షెడ్యూల్ చేస్తుంది , ఎందుకంటే మీరు కార్డ్ వివరాలు , కార్డ్ వివరాలను బట్టి మారవచ్చు .\n",
            "\n",
            "source --> once i ' re traveling abroad , the card details , expiration date ,\n",
            "target translation -->   మీరు విదేశాలకు వెళ్ళే ముందు , కార్డ్ వివరాలు , ముగింపు తేదీ , గడువు తేదీ , మొత్తం , గడువు తేదీ , , మొత్తం , <unk> లావాదేవీల తేదీ , , CVV , <unk> నిర్ధారిస్తారు .\n",
            "\n",
            "Full Translation:\n",
            "   ఖచ్చితంగా ! అంతర్జాతీయ వినియోగం కోసం మీ కార్డును సక్రియం చేయడంలో మీకు సహాయం చేయడానికి నేను ఇక్కడ ఉంటాను .\n",
            "  మీరు ఏమి చేయాలో ఇక్కడ ఉంది :\n",
            "  1 . { { కస్టమర్ సపోర్ట్ ఫోన్ నంబర్ } at వద్ద మా కస్టమర్ మద్దతు బృందాన్ని సంప్రదించండి లేదా కార్డ్ రద్దు ప్రక్రియను ప్రారంభించడానికి మా వెబ్‌సైట్‌ను { { కంపెనీ వెబ్‌సైట్ url } వద్ద సందర్శించండి .\n",
            "  2 . మీ కార్డ్ నంబర్ , కార్డ్ నంబర్ మరియు ఏదైనా అదనపు సమాచారం వంటి అవసరమైన వివరాలను అందించండి .\n",
            "  3 . మీరు ఇంతకు ముందు ఉపయోగించని తర్వాత , కార్డ్ వివరాలు , గడువు తేదీ మరియు అవసరమైన ఇతర సమాచారం వంటి నిర్దిష్ట కార్డ్ వివరాలను అందించమని మీరు అధికారం ఇవ్వాలి , అది అందించే ఇతర సమాచారం కోసం షెడ్యూల్ చేస్తుంది , ఎందుకంటే మీరు కార్డ్ వివరాలు , కార్డ్ వివరాలను బట్టి మారవచ్చు .\n",
            "  మీరు విదేశాలకు వెళ్ళే ముందు , కార్డ్ వివరాలు , ముగింపు తేదీ , గడువు తేదీ , మొత్తం , గడువు తేదీ , , మొత్తం , <unk> లావాదేవీల తేదీ , , CVV , <unk> నిర్ధారిస్తారు .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O_mB84HcAald"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}